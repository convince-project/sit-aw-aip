This project allows to use a VLM for anomaly identification.
It is possible to either use a VLM hosted locally, in a quantized form, or deployed in a distant server.
The deployment of the VLM is explained in [here](#vlm-deployement).
And the way to communicate with one of the two model choices [here](#inference-with-vlm), given [CONVINCE](https://convince-project.eu/) use cases. For now only UC1, vacuum cleaner, and UC2, assembly robot.
The last [section](#customize-communication) explains how to custom the communication.

The tests have been done only on LINUX. 

Refer to [sit-aw-api](https://convince-project.github.io/sit-aw-aip/) documentation to learn how to get started and use it.
